{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87a7b3c3",
   "metadata": {},
   "source": [
    "<div style=\"width:90%; margin:0 auto; background-color:#F0F0F0; padding:20px; border-radius:8px; font-family:Arial, sans-serif\">\n",
    "\n",
    "<div style=\"display:flex; align-items:center; justify-content:space-between; margin-bottom:15px\">\n",
    "    <div style=\"width:100px; height:100px\">\n",
    "        <img src=\"data:image/png;base64,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\" style=\"max-width:100%; max-height:100%\">\n",
    "    </div>\n",
    "    <div style=\"text-align:center; margin-bottom:20px\">\n",
    "        <h1 style=\"color:#9E0B0F; font-size:26px; margin-bottom:5px\">Análisis de modelos predictivos en bolsa</h1>\n",
    "        <h3 style=\"color:#D64550; font-size:22px; margin-top:0\">Copyright (C) 2024-2025 MegaStorm Systems</h3>\n",
    "    </div>\n",
    "    <div style=\"width:192px; height:59px\">\n",
    "        <p style=\"max-width:100%; max-height:100%\">\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "<div style=\"width:60%; margin:0 auto; background-color:#E8E8E8; padding:20px; border-radius:10px; border:1px solid #D0D0D0; margin-bottom:20px; color:#333333; line-height:1.5; box-shadow:0 2px 4px rgba(0,0,0,0.05)\">\n",
    "    <p style=\"margin:0; font-size:15px\">    \n",
    "    This software is provided \"as-is\", without any express or implied<br>\n",
    "    warranty. In no event will the authors be held liable for any damages<br>\n",
    "    arising from the use of this software.<br><br>\n",
    "    Permission is granted to anyone to use this software for any purpose,<br>\n",
    "    including commercial applications, and to alter it and redistribute it<br>\n",
    "    freely, subject to the following restrictions:<br><br>\n",
    "    1. The origin of this software must not be misrepresented; you must not<br>\n",
    "    claim that you wrote the original software. If you use this software<br>\n",
    "    in a product, an acknowledgment in the product documentation would be<br>\n",
    "    appreciated but is not required.<br>\n",
    "    2. Altered source versions must be plainly marked as such, and must not be<br>\n",
    "    misrepresented as being the original software.<br>\n",
    "    3. This notice may not be removed or altered from any source distribution.\n",
    "    </p>\n",
    "</div>\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "    <h2 style=\"font-size:24px; color:#9E0B0F; margin:0\">Predictor Random Forest v1.3</h2>\n",
    "</div>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e7b7ad-0674-4820-9e5a-616fb930fce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerías\n",
    "import os\n",
    "import argparse\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from itertools import product\n",
    "import time\n",
    "from ampblib import AMPBConfig, processData, generateEvaluation, updateNextDayExog, createReport, getExogVars, reverseTransformPredictions, createModelIdentity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea81e88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0. PARÁMETROS CONFIGURABLES\n",
    "\n",
    "model_name = \"RandomForest\"\n",
    "model_version = \"v1.3\"\n",
    "\n",
    "# Por defecto, permite ejecución interactiva\n",
    "default_exog_set_id = 16    # 1=\"Directos\", 2=\"IndicadoresTecnicos\", 3=\"BigTech\", 4=\"IndicesBursatiles\", 5=\"IndicadoresEconomicos\", 6=\"AnalisisSentimiento\"\n",
    "\n",
    "# Estos son fijos e internos\n",
    "nombre_archivo = \"NVDA_2015-01-05_2025-05-23_SA.csv\"\n",
    "test_size = 60              # Número de días para el conjunto de test\n",
    "optimize_params = True      # True para optimizar con búsqueda manual, False para usar valores fijos\n",
    "run_backtesting = True      # True para Backtesting con Walk-Forward\n",
    "retrain_interval = 1        # Reentrenar modelo completo cada n días en backtesting. 5 es un valor adecuado, acelera la velocidad a cambio de perder un ~6% de rendimiento.\n",
    "\n",
    "# No utilizamos transformaciones ni escalados, pero si se activan estos parámetros, se podrían usar en el futuro\n",
    "transformation = \"None\"\n",
    "exog_scaling = \"None\"\n",
    "\n",
    "# Parámetros por defecto (cuando no se optimiza)\n",
    "default_params = {\n",
    "    'n_estimators': 50,\n",
    "    'max_depth': None,\n",
    "    'min_samples_split': 2,\n",
    "    'min_samples_leaf': 1,\n",
    "    'max_features': 'sqrt',\n",
    "    'bootstrap': False,\n",
    "    'random_state': 42,\n",
    "    'n_jobs': -1\n",
    "}\n",
    "\n",
    "# Argumentos de línea de comandos  \n",
    "if AMPBConfig.INTERACTIVE:\n",
    "    exog_set_id = default_exog_set_id\n",
    "else:\n",
    "    parser = argparse.ArgumentParser(description='Ejecuta modelo RandomForest.')\n",
    "    def valid_exog(x):\n",
    "        if not all(c in '123456' for c in str(x)): \n",
    "            raise argparse.ArgumentTypeError(f\"Solo dígitos 1-6: {x}\")\n",
    "        return x\n",
    "    parser.add_argument('--exog_set_id', type=valid_exog, default=default_exog_set_id)\n",
    "    args = parser.parse_args()\n",
    "    exog_set_id = args.exog_set_id\n",
    "\n",
    "AMPBConfig.printHeader(title=f\"Predictor {model_name} {model_version}\", testsize=test_size, \n",
    "                     optimize=optimize_params, backtesting=run_backtesting, transform=transformation,\n",
    "                     exogscaling=exog_scaling, exogsetid=exog_set_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a741c5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. CARGA Y PREPARACIÓN DE DATOS\n",
    "datos = pd.read_csv(nombre_archivo)\n",
    "\n",
    "# Seleccionar columnas relevantes\n",
    "mandatory_vars = ['Date','Close', 'Trend']\n",
    "\n",
    "# Obtenemos lista de exogenas\n",
    "exog_vars = getExogVars(exog_set_id)\n",
    "df = datos[mandatory_vars + exog_vars]\n",
    "\n",
    "# Convertir fechas a datetime\n",
    "df['Date'] = pd.to_datetime(df['Date'])  \n",
    "\n",
    "# Verificar y mostrar estadísticas básicas de los datos\n",
    "print(f\"Datos en crudo cargados: {len(df)} registros de {df['Date'].min()} a {df['Date'].max()}.\")\n",
    "\n",
    "# Detectar valores faltantes\n",
    "missing = df.isna().sum()\n",
    "missing = missing[missing > 0]\n",
    "\n",
    "if not missing.empty:\n",
    "    total_before = len(df)\n",
    "    print(\"Valores faltantes por columna (se borrarán estas filas):\")\n",
    "    for col, cnt in missing.items():\n",
    "        print(f\"  • {col}: {cnt} valores faltantes\")\n",
    "    df = df.dropna().reset_index(drop=True)\n",
    "    total_after = len(df)\n",
    "    removed = total_before - total_after\n",
    "    print(f\"\\nFilas borradas: {removed}\")\n",
    "else:\n",
    "    print(\"No se encontraron valores faltantes.\")\n",
    "\n",
    "# Poner Date como indice\n",
    "df.set_index('Date', inplace=True)\n",
    "#df = df.asfreq('B', method='pad')  # Se asume que se trata de datos bursátiles (días hábiles)\n",
    "\n",
    "print(f\"\\nDatos cargados: {AMPBConfig.COLOR_VALUE}{len(df)}{AMPBConfig.COLOR_RESET} registros. Variables exógenas seleccionadas: {AMPBConfig.COLOR_VALUE}{len(exog_vars)}{AMPBConfig.COLOR_RESET}\\n{exog_vars}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d2b1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. DIVISIÓN ENTRE ENTRENAMIENTO Y TEST\n",
    "\n",
    "# 2A. Se utiliza el 90% de los datos para entrenamiento y el 10% para test\n",
    "#split_index = int(len(df) * 0.90)\n",
    "#df_train = df.iloc[:split_index].copy()\n",
    "#df_test = df.iloc[split_index:].copy()\n",
    "\n",
    "# 2B. Separamos datos de entrenamiento y de test por fecha\n",
    "#split_date = pd.Timestamp('2024-12-01')\n",
    "#df_train = df.loc[:split_date].copy()\n",
    "#df_test = df.loc[split_date:].copy()\n",
    "\n",
    "# 2C. Separamos por numero de dias.\n",
    "df_train = df.iloc[:-test_size]\n",
    "df_test = df.iloc[-test_size:]\n",
    "\n",
    "# Guardar valores originales (inmutables para referencia futura)\n",
    "y_train_original = df_train['Close'].copy()\n",
    "y_test_original = df_test['Close'].copy()\n",
    "X_train_original = df_train[exog_vars].copy()  \n",
    "X_test_original = df_test[exog_vars].copy()\n",
    "\n",
    "# Variables de trabajo (se transformarán/escalarán según configuración)\n",
    "y_train = df_train['Close']\n",
    "y_test  = df_test['Close']\n",
    "X_train = df_train[exog_vars].copy()\n",
    "X_test = df_test[exog_vars].copy()\n",
    "\n",
    "print(f\"\\nDatos divididos:\")\n",
    "print(f\"  Entrenamiento: {AMPBConfig.COLOR_VALUE}{len(y_train)}{AMPBConfig.COLOR_RESET} filas (hasta {y_train.index[-1].date()})\")\n",
    "print(f\"  Test:          {AMPBConfig.COLOR_VALUE}{len(y_test)}{AMPBConfig.COLOR_RESET} filas (desde {y_test.index[0].date()})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef9b3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. PROCESAR DATOS: TRANSFORMACIONES, ESCALADO, ALINEACION Y ANALISIS DE CALIDAD\n",
    "# Bajo determinadas circunstancias, puede abortar la ejecucion.\n",
    "processing_results = processData(\n",
    "    y_train, y_test, X_train, X_test,\n",
    "    y_train_original, y_test_original, X_train_original, X_test_original,\n",
    "    df_test, exog_vars, transformation, exog_scaling,\n",
    "    winsorization_value=0,   \n",
    "    analyze=False               # True para ejecutar análisis de calidad\n",
    ")\n",
    "params_close = processing_results['params_close']\n",
    "y_scaler = processing_results['y_scaler']\n",
    "df_test_aligned = processing_results['df_test_aligned']\n",
    "prediction_max_limit = processing_results['prediction_max_limit']\n",
    "quality_results = processing_results['quality_results']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396dd3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. ENTRENAMIENTO RANDOM FOREST (SOLO EN TRAIN DATA)\n",
    "    \n",
    "# 4A. OPTIMIZACIÓN DE HIPERPARÁMETROS CON GRID SEARCH\n",
    "if optimize_params:\n",
    "    print(\"Buscando los mejores hiperparámetros para Random Forest...\")\n",
    "        \n",
    "    # Grid de parámetros para optimización\n",
    "    param_grid = {\n",
    "        'n_estimators': [50, 100, 150, 200],\n",
    "        'max_depth': [10, 15, 20, None],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4],\n",
    "        'max_features': ['sqrt', 'log2', None],\n",
    "        'bootstrap': [True, False]\n",
    "    }       \n",
    "    \n",
    "    # Generar todas las combinaciones posibles\n",
    "    param_combinations = list(product(*param_grid.values()))\n",
    "    param_names = list(param_grid.keys())\n",
    "\n",
    "    best_mae = float('inf')\n",
    "    best_params_found = None\n",
    "    total_combinations = len(param_combinations)\n",
    "\n",
    "    print(f\"Evaluando {total_combinations} combinaciones de hiperparámetros...\")\n",
    "\n",
    "    for i, param_values in enumerate(param_combinations):\n",
    "        progress_perc = (i + 1) / total_combinations * 100\n",
    "        print(f\" Optimización Random Forest: {i+1}/{total_combinations} ({progress_perc:.1f}%)\", end='\\r', flush=True)\n",
    "        \n",
    "        # Crear diccionario de parámetros\n",
    "        current_params = dict(zip(param_names, param_values))        \n",
    "        current_params['n_jobs'] = -1 \n",
    "        \n",
    "        try:\n",
    "            # Crear y entrenar modelo con todos los datos de entrenamiento\n",
    "            model_temp = RandomForestRegressor(**current_params)\n",
    "            model_temp.fit(X_train, y_train)\n",
    "            \n",
    "            # Hacer predicción en los mismos datos de entrenamiento\n",
    "            train_predictions = model_temp.predict(X_train)\n",
    "            \n",
    "            # Calcular MAE en entrenamiento\n",
    "            mae = np.mean(np.abs(train_predictions - y_train.values))\n",
    "            \n",
    "            # Actualizar mejor modelo si es necesario\n",
    "            if mae < best_mae:\n",
    "                best_mae = mae\n",
    "                best_params_found = current_params.copy()\n",
    "               \n",
    "        except Exception as e:\n",
    "            # Si el modelo falla, continuar con la siguiente combinación\n",
    "            print(f\"Error explorando {current_params}\")\n",
    "            continue\n",
    "\n",
    "    print(f\"\\nMejor MAE en entrenamiento: {best_mae:.4f}\")\n",
    "    best_params = best_params_found\n",
    "\n",
    "# 4B. USAR HIPERPARÁMETROS FIJOS\n",
    "else:   \n",
    "    # Usar hiperparámetros fijos\n",
    "    best_params = default_params.copy()\n",
    "\n",
    "# 4C. AJUSTE DE RANDOM FOREST\n",
    "print(\"Ajustando modelo...\")\n",
    "best_model = RandomForestRegressor(**best_params)\n",
    "best_model.fit(X_train, y_train)\n",
    "    \n",
    "# Creamos el título (y su hash) y mostramos resultados\n",
    "param_str = f\"({best_params['n_estimators']},{best_params['max_depth']},{best_params['min_samples_split']},{best_params['min_samples_leaf']},{best_params['max_features']})\"\n",
    "model_title, model_hash = createModelIdentity(\"RF\", model_version, param_str, transformation, exog_scaling, exog_set_id)\n",
    "print(f\"\\n{AMPBConfig.COLOR_INFO}Parametros para {model_name}{model_version}:{AMPBConfig.COLOR_RESET}\")\n",
    "print(f\"Hiperparámetros utilizados:\")\n",
    "for param, value in best_params.items():\n",
    "    print(f\"  {param}: {value}\")\n",
    "print(f\"\\nTítulo: '{model_title}' con HashID: {model_hash}\\n\")\n",
    "\n",
    "# Mostrar importancia de features (top 10)\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': exog_vars,\n",
    "    'importance': best_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(f\"Top 10 features más importantes:\")\n",
    "for i, (_, row) in enumerate(feature_importance.head(10).iterrows()):\n",
    "    print(f\"  {i+1}. {row['feature']}: {row['importance']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc461ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5A. PREDICCIÓN Y EVALUACIÓN EN EL CONJUNTO DE TEST (VALIDACIÓN ESTÁTICA)\n",
    "print(f\"{AMPBConfig.COLOR_INFO}Validación Estática{AMPBConfig.COLOR_RESET}\")\n",
    "\n",
    "# Predicción del período de test completo\n",
    "forecast_scaled_transformed = best_model.predict(X_test)\n",
    "forecast_scaled_transformed = pd.Series(forecast_scaled_transformed, index=y_test.index)\n",
    "\n",
    "# Aplicar pipeline de des-transformación\n",
    "forecast_original = reverseTransformPredictions(\n",
    "    forecast_scaled_transformed,\n",
    "    y_train_original.iloc[-1],\n",
    "    y_scaler,\n",
    "    transformation, \n",
    "    params_close,\n",
    "    prediction_max_limit\n",
    ")\n",
    "\n",
    "# Predicción día siguiente\n",
    "X_next_day = updateNextDayExog(\n",
    "    X_test, \n",
    "    feature_original_close=y_test_original.iloc[-1], \n",
    "    transformation=transformation,\n",
    "    params_exog=None,\n",
    "    exog_scaler=None,\n",
    "    prev_open_original=None\n",
    ")\n",
    "\n",
    "next_day_date = y_test.index[-1] + pd.tseries.offsets.BDay(1)\n",
    "X_next_day.index = [next_day_date]\n",
    "\n",
    "next_forecast_scaled_transformed = best_model.predict(X_next_day)\n",
    "next_forecast_scaled_transformed = pd.Series(next_forecast_scaled_transformed, index=[next_day_date])\n",
    "\n",
    "next_day_forecast_original = reverseTransformPredictions(\n",
    "    next_forecast_scaled_transformed, \n",
    "    y_test_original.iloc[-1], # Para la referencia del día siguiente, usar el último valor real del test\n",
    "    y_scaler,\n",
    "    transformation,\n",
    "    params_close,\n",
    "    prediction_max_limit\n",
    ").iloc[0]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ceab91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5B. EVALUACIÓN Y GRÁFICAS \n",
    "# Evaluación de validación estática\n",
    "sv_r2, sv_mae, sv_rmse, sv_accuracy, sv_f1_score, sv_roc_auc = generateEvaluation(\n",
    "    y_test_original, forecast_original, df_test_aligned, model_title, model_hash, \n",
    "    next_day_date, next_day_forecast_original, \"Static Validation\")\n",
    "\n",
    "# Guardar reporte\n",
    "createReport(model_name, \"SV\", f\"{exog_set_id}\", model_title, model_hash,  sv_r2, sv_mae, sv_rmse, sv_accuracy, sv_f1_score, sv_roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e83975e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. EVALUACIÓN CON CROSS VALIDATION (VALIDACIÓN CRUZADA)\n",
    "# Opcional, no disponible en este modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552e6567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7A. MODO DE BACKTESTING: PREDICCIÓN DÍA A DÍA (VALIDACIÓN BACKTESTING)\n",
    "if run_backtesting:    \n",
    "    model_title_backtest = f'{model_title} (Backtesting [{retrain_interval}d])'\n",
    "    print(f\"\\n{AMPBConfig.COLOR_INFO}Modo Backtesting con Walk-Forward (Retrain cada {retrain_interval} días){AMPBConfig.COLOR_RESET}\")\n",
    "    \n",
    "    # Inicializar historiales\n",
    "    history_y = y_train.copy()              # Datos transformados/escalados para el modelo\n",
    "    history_X = X_train.copy()              # Datos transformados/escalados para el modelo\n",
    "    history_y_original = y_train_original.copy()  # Valores originales para referencias\n",
    "    \n",
    "    predictions_original_bt = []\n",
    "    model_bt = None  # Modelo que se reutilizará entre reentrenamientos\n",
    "    \n",
    "    bt_start = time.time()\n",
    "    for t in range(len(y_test)):\n",
    "        print(f\" Backtesting: {t+1}/{len(y_test)}\", end='')\n",
    "        \n",
    "        # Reentrenar el modelo cuando sea necesario\n",
    "        if t % retrain_interval == 0:   \n",
    "            print(f\" [Reentrenando...]\", end='')\n",
    "            model_bt = RandomForestRegressor(**best_params)\n",
    "            model_bt.fit(history_X, history_y)\n",
    "            print(f\" [✓]\", end='')\n",
    "        \n",
    "        print(f\"\")  # Nueva línea\n",
    "        \n",
    "        # Preparar exógenas propagadas\n",
    "        X_current = updateNextDayExog(\n",
    "            history_X, \n",
    "            feature_original_close=history_y_original.iloc[-1],        # Close_{t-1} original \n",
    "            transformation=transformation,\n",
    "            params_exog=None,\n",
    "            exog_scaler=None,\n",
    "            prev_open_original=None\n",
    "        )\n",
    "\n",
    "        \n",
    "        # Predecir 1 paso adelante (Random Forest)\n",
    "        forecast_step_prediction = model_bt.predict(X_current)\n",
    "        forecast_step_scaled_transformed = pd.Series(forecast_step_prediction, index=X_current.index)\n",
    "        \n",
    "        # Des-transformar usando pipeline centralizado \n",
    "        reference_val = history_y_original.iloc[-1]\n",
    "        forecast_step_original = reverseTransformPredictions(\n",
    "            forecast_step_scaled_transformed,\n",
    "            reference_val,\n",
    "            y_scaler,\n",
    "            transformation,\n",
    "            params_close,\n",
    "            prediction_max_limit\n",
    "        ).iloc[0]\n",
    "                \n",
    "        # Guardar predicción\n",
    "        predictions_original_bt.append(forecast_step_original)\n",
    "        \n",
    "        # Actualizar historiales con datos reales del día t\n",
    "        history_y = pd.concat([history_y, y_test.iloc[t:t+1]])\n",
    "        history_X = pd.concat([history_X, X_test.iloc[t:t+1]])\n",
    "        history_y_original = pd.concat([history_y_original, pd.Series([y_test_original.iloc[t]], index=[y_test_original.index[t]])])\n",
    "    \n",
    "    # Estadísticas de reentrenamiento\n",
    "    total_retrains = (len(y_test) + retrain_interval - 1) // retrain_interval  \n",
    "    print(f\" Backtesting completado en {time.time() - bt_start:.1f}s\")\n",
    "    print(f\" Reentrenamientos realizados: {total_retrains} (cada {retrain_interval} días)\\n\")\n",
    "    \n",
    "    # Crear Serie con predicciones del backtesting\n",
    "    forecast_backtest_original = pd.Series(predictions_original_bt, index=y_test_original.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7f029c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7B. MODO DE BACKTESTING: PREDICCIÓN SIGUIENTE DÍA\n",
    "if run_backtesting:\n",
    "    # Predicción para el día siguiente usando el último modelo del backtesting\n",
    "    X_next_day_bt = updateNextDayExog(\n",
    "            history_X, \n",
    "            feature_original_close=history_y_original.iloc[-1],    \n",
    "            transformation=transformation,\n",
    "            params_exog=None,\n",
    "            exog_scaler=None,\n",
    "            prev_open_original=None\n",
    "        )\n",
    "    X_next_day_bt.index = [next_day_date]   \n",
    "    # Predecir y des-transformar usando pipeline centralizado (Random Forest)\n",
    "    next_forecast_prediction_bt = model_bt.predict(X_next_day_bt)\n",
    "    next_forecast_scaled_transformed_bt = pd.Series(next_forecast_prediction_bt, index=[next_day_date])\n",
    "    next_day_forecast_val_bt_original = reverseTransformPredictions(\n",
    "        next_forecast_scaled_transformed_bt, \n",
    "        history_y_original.iloc[-1], # Predicción para el día siguiente usando el último modelo del backtesting\n",
    "        y_scaler, \n",
    "        transformation, \n",
    "        params_close,\n",
    "        prediction_max_limit\n",
    "    ).iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b4cf3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7C. MODO DE BACKTESTING: EVALUACIÓN Y GRÁFICAS\n",
    "if run_backtesting:\n",
    "    # Evaluación del backtesting\n",
    "    bt_r2, bt_mae, bt_rmse, bt_accuracy, bt_f1_score, bt_roc_auc = generateEvaluation(\n",
    "        y_test_original, \n",
    "        forecast_backtest_original, \n",
    "        df_test_aligned, \n",
    "        model_title_backtest, \n",
    "        model_hash,\n",
    "        next_day_date, \n",
    "        next_day_forecast_val_bt_original, \n",
    "        \"Backtesting\"\n",
    "    )\n",
    "\n",
    "    # Guardar informe del backtesting\n",
    "    createReport(model_name, \"BT\", f\"{exog_set_id}\", model_title, model_hash,  bt_r2, bt_mae, bt_rmse, bt_accuracy, bt_f1_score, bt_roc_auc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
